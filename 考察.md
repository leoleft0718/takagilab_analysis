## 📊 実験データ分析結果

**分析日**: 2026年1月5日

---

## 1. 実験概要

### 1.1 目的

LLMを用いて学習者の**主観的難易度（自信度・挑戦度）**を推定し、「自信＝挑戦度」となる問題を推薦するシステムの評価。

### 1.2 実験設計

| 項目 | 値 |
| --- | --- |
| 対象領域 | 線形代数（行列式） |
| 問題数 | 35問 |
| 被験者 | 大学生・大学院生 10人 |
| セッション数 | 11セッション |
| 総回答数 | 300件 |
| LLM | Gemini 3.0 Pro |

### 1.3 実験フロー

1. **診断フェーズ**: 問題に解答し、自信度・挑戦度（1〜6）を入力
2. **推薦フェーズ**: LLMが診断結果から最適な問題を推薦
3. **最終評価フェーズ**: 全問題の自信度・挑戦度をユーザーが評価し、AI予測と比較

**注**: 問題の出題順序は各セッションでランダム化された。

### 1.4 評価指標

| 指標 | 計算方法 | 意味 |
| --- | --- | --- |
| **GAP** | 自信度 − 挑戦度 | 正: 簡単すぎる、0: 適切、負: 難しすぎる |
| **MAE** | 平均絶対誤差 | 予測と実際の平均的なずれ（小さいほど良い） |
| **相関係数** | ピアソン相関 | 予測と実際の傾向の一致度（1に近いほど良い） |
| **完全一致率** | 予測 = 実際 の割合 | ピッタリ当たる確率 |
| **±1以内** | |予測 - 実際| ≤ 1 の割合 | ほぼ当たる確率 |

---

## 2. ベースライン比較

### 2.1 ベースラインの定義

| ベースライン | 予測方法 | 検証できること |
| --- | --- | --- |
| **全体平均** | 全データの平均値を予測値とする | 最も単純な予測との差 |
| **問題平均** | 各問題の全ユーザー平均を予測値とする | LLMが**ユーザー差**を捉えているか |
| **ユーザー平均** | 各ユーザーの全問題平均を予測値とする | LLMが**問題差**を捉えているか |

### 2.2 自信度予測の結果

| ベースライン | MAE | 相関係数 | R² | 完全一致率 | ±1以内 |
| --- | --- | --- | --- | --- | --- |
| **LLM予測** | **1.09** | **0.600** | **0.360** | **32.7%** | **63.7%** |
| 全体平均 | 1.65 | 0 | 0 | 8% | 22% |
| 問題平均 | 1.35 | 0.467 | 0.218 | 16% | 48% |
| ユーザー平均 | 1.30 | 0.457 | 0.209 | 21.3% | 44.7% |

<aside>
✅

**結論**: 自信度予測は**全指標で全ベースラインに勝利**

</aside>

### 2.3 挑戦度予測の結果

| ベースライン | MAE | 相関係数 | R² | 完全一致率 | ±1以内 |
| --- | --- | --- | --- | --- | --- |
| **LLM予測** | 1.23 | 0.371 | 0.138 | — | — |
| 全体平均 | 1.18 | 0 | 0 | — | — |
| **問題平均** | **0.94** | **0.500** | — | — | — |
| ユーザー平均 | 1.01 | 0.347 | — | — | — |

<aside>
❌

**結論**: 挑戦度予測は**全ベースラインに敗北**。問題平均が最も精度が高い。

</aside>

### 2.4 GAP予測の結果

| ベースライン | MAE | 相関係数 | R² | 完全一致率 | ±1以内 |
| --- | --- | --- | --- | --- | --- |
| **LLM予測** | 2.11 | **0.532** | **0.283** | **21.7%** | **42.3%** |
| 全体平均 | 2.68 | 0 | 0 | 4% | 7% |
| **問題平均** | **2.07** | 0.513 | 0.263 | 14% | 35% |
| ユーザー平均 | 2.20 | 0.403 | 0.162 | 19% | 28.3% |

<aside>
⚠️

**結論**: MAEでは問題平均に僅差で負けるが、**相関・完全一致率・±1以内ではLLMが勝利**

</aside>

### 2.5 自信度 vs 挑戦度の比較

| 指標 | 自信度 | 挑戦度 |
| --- | --- | --- |
| 相関係数 | **0.600** ✅ | 0.371 |
| MAE | **1.09** ✅ | 1.23 |
| 平均差分 | 0.02（ほぼ一致） | +0.51（過大評価） |
| vs ベースライン | **全勝** | **全敗** |

---

## 3. LLMが捉えている情報の分析

### 3.1 残差相関分析

「LLMがユーザーごとの違いを捉えているか」を検証するため、問題効果を除去した残差相関を分析した。

| 指標 | 値 | 意味 |
| --- | --- | --- |
| 全体相関 | 0.532 | 問題差 + ユーザー差 が混在 |
| **残差相関** | **0.358** | 問題効果を除去後の相関 |
| 問題内相関の平均 | 0.330 | 各問題内でのユーザー差の捕捉 |

**解釈**: 残差相関 0.358 は、問題効果を除いた後もLLMがユーザー差を捉えていることを示す。

### 3.2 混合効果モデル分析

問題効果・ユーザー効果を統計的に分離し、LLMの独立した寄与を検証した。

- モデルの数式
    
    **線形混合モデル（Linear Mixed Model）**
    
    $$
    y_{ij} = \beta_0 + \beta_1 \cdot \text{ai\_gap}_{ij} + u_i + v_j + \varepsilon_{ij}
    $$
    
    | 記号 | 意味 |
    | --- | --- |
    | $y_{ij}$ | ユーザー $i$ の問題 $j$ に対する Human GAP |
    | $\beta_0$ | 切片（固定効果） |
    | $\beta_1$ | LLM予測の係数（固定効果） |
    | $\text{ai\_gap}_{ij}$ | LLMが予測した AI GAP |
    | $u_i$ | ユーザー $i$ のランダム効果: $u_i \sim N(0, \sigma^2_u)$ |
    | $v_j$ | 問題 $j$ のランダム効果: $v_j \sim N(0, \sigma^2_v)$ |
    | $\varepsilon_{ij}$ | 残差: $\varepsilon_{ij} \sim N(0, \sigma^2_\varepsilon)$ |
- 分散成分の計算
    
    **級内相関係数（ICC: Intraclass Correlation Coefficient）**
    
    $$
    \text{ICC}_{\text{user}} = \frac{\sigma^2_u}{\sigma^2_u + \sigma^2_v + \sigma^2_\varepsilon}
    $$
    
    $$
    \text{ICC}_{\text{problem}} = \frac{\sigma^2_v}{\sigma^2_u + \sigma^2_v + \sigma^2_\varepsilon}
    $$
    
    | 成分 | 値 | 計算 |
    | --- | --- | --- |
    | $sigma^2_v$（問題） | 27.1% | 問題間の分散 |
    | $sigma^2_u$（ユーザー） | 10.2% | ユーザー間の分散 |
    | $sigma^2_varepsilon$（残差） | 62.7% | 説明できない分散 |
- R²の計算（Nakagawa & Schielzeth, 2013）
    
    **周辺R²（Marginal R²）**: 固定効果のみの説明力
    
    $$
    R^2_m = \frac{\text{Var}(\hat{y}_{\text{fixed}})}{\text{Var}(\hat{y}_{\text{fixed}}) + \sigma^2_u + \sigma^2_v + \sigma^2_\varepsilon}
    $$
    
    **条件付きR²（Conditional R²）**: 固定効果 + ランダム効果の説明力
    
    $$
    R^2_c = \frac{\text{Var}(\hat{y}_{\text{fixed}}) + \sigma^2_u + \sigma^2_v}{\text{Var}(\hat{y}_{\text{fixed}}) + \sigma^2_u + \sigma^2_v + \sigma^2_\varepsilon}
    $$
    
    | 指標 | 値 | 意味 |
    | --- | --- | --- |
    | $R^2_m$ | 10.0% | LLM予測のみの説明力 |
    | $R^2_c$ | 37.3% | 全効果の説明力 |

**分散成分（Variance Components）**

| 成分 | 値 | 意味 |
| --- | --- | --- |
| 問題効果 | 27.1% | GAPのばらつきの約1/4は問題の違いで説明 |
| ユーザー効果 | 10.2% | GAPのばらつきの約1/10は人の違いで説明 |
| 残差 | 62.7% | 問題×ユーザーの個別の違い + ノイズ |

**LLM予測の固定効果**

| 指標 | 値 | 意味 |
| --- | --- | --- |
| 係数 (β) | **0.524** | AI GAPが1上がるとHuman GAPが0.524上がる |
| p値 | **< 0.001** | 統計的に非常に有意 |
| 周辺R² | **10.0%** | LLM予測のみで説明できる分散の割合 |
| 条件付きR² | 37.3% | 全効果で説明できる割合 |

<aside>
✅

**結論**: LLMは問題効果・ユーザー効果を制御した後も**有意な寄与**を示した（p < 0.001）

</aside>

**解釈**: 周辺R² = 10%は問題効果・ユーザー効果とは独立した追加の説明力を表す。ただし、LLMは問題効果やユーザー効果自体も部分的に捉えていると考えられるため、LLM予測の全体的な寄与はこれを上回ると推測される。

- 周辺R²と条件付きR²の違い
    
    
    | 指標 | 使う情報 | 値 | 意味 |
    | --- | --- | --- | --- |
    | **周辺R²** | LLM予測のみ | 10.0% | 「誰か」「どの問題か」を知らなくても説明できる割合 |
    | **条件付きR²** | LLM + ユーザー + 問題 | 37.3% | 「この人」「この問題」がわかれば説明できる割合 |
    
    **具体例**: 新しいユーザーが来たとき、LLM予測だけで10%の説明力。既知のユーザー・問題なら37.3%の説明力。
    
- 残差62.7%の解釈
    
    残差は「全てランダムなノイズ」ではない。
    
    | 成分 | 説明 |
    | --- | --- |
    | 真のノイズ | 測定誤差、気分の変動など |
    | 問題×ユーザー交互作用 | 「山田さんは計算問題だけ苦手」など、モデルが捉えていない個別の組み合わせ効果 |
    | その他の未測定要因 | 問題の見た目、疲労など |
    
    より複雑なモデル（ランダム傾きなど）を使えば、一部は説明可能な可能性がある。
    

### 3.3 残差診断

混合効果モデルの仮定（残差の正規性）を検証した。

**残差の統計量**

| 指標 | 値 | 基準 | 判定 |
| --- | --- | --- | --- |
| 平均 | -0.0000 | ≈ 0 | ✅ 完璧 |
| 歪度 | -0.33 | |値| < 1 * | ✅ 許容範囲 |
| 尖度 | -0.21 | |値| < 2 * | ✅ 許容範囲 |
| W統計量 | 0.9875 | ≥ 0.95 | ✅ 正規分布に近い |

* 歪度・尖度の基準は統一的な定義はなく、経験的なガイドライン（Bulmer, 1979; George & Mallery, 2010）。

**Shapiro-Wilk検定**

- W = 0.9875, p = 0.011
- 結果: 正規性は統計的に棄却（p < 0.05）

<aside>
✅

**判定**: 歪度・尖度は許容範囲内、W統計量も高い（0.98以上）。Shapiro-Wilk検定はサンプルサイズに敏感なため、実質的な逸脱は軽微と判断。

</aside>

- なぜ残差は正規分布に近いのか
    1. **中心極限定理**: 残差は多くの小さな要因（測定誤差、気分、集中度など）の合計。多くの独立した要因が足し合わさると正規分布に近づく。
    2. **モデルが系統的変動を吸収**: 問題効果・ユーザー効果・LLM予測で系統的なパターンを除去した後、残るのはランダムなばらつき。
    3. **良い兆候**: 残差が正規分布に近いのは、モデルが適切にフィットしている証拠。

### 3.4 尺度の妥当性検証

自信度・挑戦度はリッカート尺度（1〜6）であり、厳密には順序尺度である。これを間隔尺度として扱いピアソン相関を用いることの妥当性を検証するため、スピアマンの順位相関係数と比較した。

**相関係数の比較**

| 指標 | ピアソン (r) | スピアマン (ρ) | 差 | 判定 |
| --- | --- | --- | --- | --- |
| 自信度 | 0.600 | 0.576 | 0.024 | ✅ 一致 |
| 挑戦度 | 0.371 | 0.360 | 0.011 | ✅ 一致 |
| GAP | 0.532 | 0.507 | 0.025 | ✅ 一致 |

<aside>
✅

**結論**: 全ての指標で差 < 0.05。リッカート尺度を間隔尺度として扱うパラメトリック分析の妥当性が支持された。

</aside>

- なぜこの検証が必要なのか
    
    **問題の背景:**
    
    - リッカート尺度は「1と2の差」と「5と6の差」が心理的に等間隔とは限らない
    - ピアソン相関は間隔尺度を仮定するため、順序尺度では不適切な可能性がある
    
    **検証方法:**
    
    - スピアマン相関は順位のみを使うため、順序尺度でも適切
    - ピアソンとスピアマンが近ければ、間隔尺度として扱っても問題ない
    
    **結果の意味:**
    
    - 差が0.05未満 → 尺度の扱い方が結果にほぼ影響しない
    - 心理学・教育工学の慣例（Carifio & Perla, 2007; Norman, 2010）とも整合

---

## 4. 主要な発見

### 4.1 成功点

<aside>
✅

**自信度予測は成功**: LLMは全ベースラインに勝利（MAE 1.09, r = 0.600）

</aside>

<aside>
✅

**LLMはユーザー差を捉えている**: 残差相関 0.358、混合効果モデルで有意な寄与

</aside>

### 4.2 課題

<aside>
❌

**挑戦度予測は課題**: 全ベースラインに敗北、+0.51の過大評価バイアス

</aside>

<aside>
⚠️

**GAP予測のMAEは問題平均に僅差で負け**: 2.11 vs 2.07

</aside>

---

## 5. 限界

### 5.1 サンプルサイズの制約

ユーザー数が10人と限定的であり、混合効果モデルのランダム効果（ユーザー効果）の推定は不安定である可能性がある。一般的に混合効果モデルではグループ数（ユーザー数）20〜30以上が推奨される。本研究は探索的な分析として位置づけ、今後はより大規模なサンプルでの検証が必要である。

### 5.2 差得点（GAP）の信頼性

GAPは自信度と挑戦度の差分として定義される派生指標であり、測定誤差が加算される性質上、信頼性が低下する可能性がある。本研究では自信度・挑戦度の個別予測を主要な評価指標とし、GAPは参考指標として報告した。

### 5.3 尺度の扱い

自信度・挑戦度はリッカート尺度（1〜6）であり、厳密には順序尺度である。これを間隔尺度として扱いピアソン相関を用いることの妥当性を検証するため、スピアマンの順位相関係数と比較した。結果、差は全で0.05未満であり、間隔尺度として扱うことの妥当性が支持された（Carifio & Perla, 2007; Norman, 2010）。

### 5.4 その他の限界

- IRT/BKT等の従来手法との比較は未実施
- 対象領域が行列式に限定
- 単一のLLM（Gemini 3.0 Pro）のみで検証

---

## 6. 分析の整理と今後の方針

### Part 1: 予測精度の分析【完了】

**目的**: LLMは人間のGAPをどの程度予測できるか

| 分析項目 | 主な結果 |
| --- | --- |
| **ベースライン比較** | 自信度は全勝、挑戦度は全敗、GAPは一部勝利 |
| **混合効果モデル** | LLMは問題・ユーザー効果を制御後も有意な寄与（p < 0.001） |
| **分布の比較** | AIは予測を0付近に集中させる「平均への回帰」傾向 |
| **混同行列** | 極端なGAP（+4〜+5）の予測精度は高いが、GAP=0付近は低い |

<aside>
📊

**結論**: LLMは**傾向（相関）は捉えている**が、**振れ幅を過小評価**している

</aside>

---

### Part 2: 推薦システムの設計【検討中】

**課題**: 予測精度の限界を踏まえ、どう推薦するか

| 検討事項 | 現状の結論 |
| --- | --- |
| **当初目標（GAP=0）** | Precision 27%、Lift 1.35 → 推薦システムとして不十分 |
| **目標変更（|GAP| ≤ 1）** | Precision 40%、Lift 1.30 → 改善するが劇的ではない |
| **代替案** | 補正アプローチ、二段階フィルタリング等を検討中 |

<aside>
🎯



</aside>

---
